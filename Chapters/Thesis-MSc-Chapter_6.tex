% #############################################################################
% This is Chapter 6
% !TEX root = ../main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{System Evaluation}
\cleardoublepage
% The following line allows to ref this chapter
\label{chap:evaluation}

This chapter concerns the system and board evaluation. The system and board were evaluated regarding its perfromance and the fullfilled requirements outlined in the previous project report and the problem definition chapter \ref{chap:problem}.
% -----------------------------------------------------
% -----------------------------------------------------
\section{Performance Tests}\label{chap:evaluation:performance}

The test objectives, configuration, results and conclusions are detailed for every tested component.
The communication channel, smartfusion2 board's security services and implemented services were tested.
The measured performance metrics were the processing time for every test, and the tested component's throughput.

% -----------------------------------------------------
\subsection{Testing configuration}\label{chap:evaluation:performance:config}

The tests were all performed on a Windows 10 computer, connected to the HSM device through a \ac{UART} serial port. The implemented PKCS\#11 program interface was used to run the tests.
Two programs were running on the computer while performing the tests, the client program on powershell and the SoftConsole IDE to run the code on the smartfusion board.
For all tests, the serial port UART connection was configured with a 115200 bit/s baud rate, 8 data bits, no parity bits and one stop bit.
The elapsed time was measured in the client application using the function \texttt{gettimeofday()} available in the C library \texttt{sys/time.h}.

In order to thoroughly study the performance and scalability of each component, the transmitted data size was varied, only for components where it is logical and can potentially have a performance impact.
Since the board does not provide a clock and \ac{API} to measure elapsed time, the time has to be measured on the client's side.
Time measurement starts in the client interface right before sending a message to the device which triggers the operation, and stops when the client receives a message from the device, after the operation is finished.
Tests were performed in two different configurations.
For the first, the measured operation is performed once in the device each transmission. This transmission is repeated multiple times for every set of values, until an acceptable variance is achieved. For most components the variance is well bellow 1\%. The more volatile test results have a variance below 4\%.
Obvious outlier values were excluded from the experimental calculations. The adopted rule was that values which are significantly above or below the average, and are never repeated were eliminated from the sample set.
For the second scenario, tests on components where the time to transmit messages needed to minimized to more accurately assess the corresponding component's performance, for each transmission the operation was performed 50 times. The resulting time was divided by 50 to obtain the processing time per operation.

% -----------------------------------------------------
\subsection{Communications}\label{chap:evaluation:performance:comms}

In order to assess the communication channel performance, the average time to transmit data was measured. The client sent the data and the device sent the data back immediately without performing another operation. The test, in accordance with the first scenario, was repeated at least 30 times for each data length. The highest variance did not go above 0.2\%.
The average transmission times for each value are displayed in figure \ref{fig:comms:time}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\textwidth]{./Images/comms-time.png}
	\caption{Average Data Transmission Times}
	\label{fig:comms:time}
\end{figure}

The values range from 0.016 seconds for 50 bytes, to 2.6 seconds for 29 KBytes.
From the graph we can conclude the performance has linear scalability which is ideal for a system.

For the subsequent graphic, the throughput was calculated from the transmission tests, for every repetition.
Figure~\ref{fig:comms:tput} plots the experimental throughput and theoretical throughput. The theoretical throughput was calculated from the baud rate \(115200/8 = 14.06 KBytes/s\).
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.8\textwidth]{./Images/comms-tput.png}
	\caption{Serial Port Communications Throughput}
	\label{fig:comms:tput}
\end{figure}

We observe the experimental throughput is 3.05 KB/s for data below 100 bytes and starts stabilizing around 12 KB/s to 11 KB/s as data size increases.
Thus we can conclude the practical throughput is close to the theoretical, and as expected stabilizes as the sample size increases, meaning, more bytes are transmitted.

% -----------------------------------------------------
% -----------------------------------------------------
\section{Smartfusion2 Security Services}\label{chap:evaluation:board}

\subsection{AES-128 and AES-256}\label{chap:evaluation:board:aes}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{./Images/aes128-compare.png}
	\caption{AES 128 processing time}
	\label{fig:performance:aes128:compare}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{./Images/aes256-compare.png}
	\caption{AES 256 processing time}
	\label{fig:performance:aes256:compare}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{./Images/aes128-tput.png}
	\caption{AES Throughput}
	\label{fig:performance:aes:tput}
\end{figure}

% -----------------------------------------------------
\subsection{SHA-256 Based Services}\label{chap:evaluation:board:sha}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{./Images/sha-compare.png}
	\caption{SHA based services processing time}
	\label{fig:performance:sha:compare}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{./Images/sha-tput.png}
	\caption{SHA based services throughput}
	\label{fig:performance:sha:tput}
\end{figure}

% -----------------------------------------------------
% -----------------------------------------------------
\section{Implemented Services}\label{chap:evaluation:services}

The same library used to measure the time in the communication tests was used.
The time was measured at the client application before sending the message which will trigger the service at the HSM, and after it has received the result.

In order to get a real time measurement, each operation was performed 1000 times on the HSM, with the communications only done once.
From the resulting time, the predicted time spent on communications was subtracted using the data from the previous test. The result was then divided by 1000.

The data encryption and decryption operations were ran with different data sizes, in order to asses the data size impact on performance.
The ECDH key generation always uses a private and public key of the same size, so no message size variation is possible.

% -----------------------------------------------------
\subsection{Secure Communications}\label{chap:evaluation:services:comms}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{./Images/op3-time.png}
	\caption{Secure Communications Average Time}
	\label{fig:performance:op34-time}
\end{figure}

The results in table~\ref{fig:performance:op34-time} for the encryption and decryption operations are very similar due to both using the same board services, AES encryption and HMAC, but in a different order. It is also important to note AES encryption and decryption in CTR mode is essentially the same operation due the mode's characteristics.
Relating to the variation in data size, the values vary between approximately 0.1284 and 0.1825 seconds, which is a very insignificant difference. Thus we can conclude, the data size has a negligible impact on the operations performance.

% -----------------------------------------------------
\subsection{Import Keys}\label{chap:evaluation:services:import-key}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{./Images/import-time.png}
	\caption{Import Keys Average Time}
	\label{fig:performance:import-time}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{./Images/services-compare-tput.png}
	\caption{Implemented Services Throughput Comparison}
	\label{fig:performance:services-tput}
\end{figure}

% -----------------------------------------------------
\subsection{Key Generation}\label{chap:evaluation:services:key-gen}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.45\textwidth]{./Images/op8-time.png}
	\caption{Key Generation Average Time}
	\label{fig:performance:op8-time}
\end{figure}

Regarding the key generation operation results in table~\ref{fig:performance:op8-time}, two values were obtained through different methods. Due to the operation using SRAM-PUF services to enroll new keys in the eNVM memory, with limited write cycles and key slots, this operation cannot be repeated enough times to get a relevant enough sample size.
So a trade off was achieved. The operation was performed 1000 times without the key enrollment operation, meaning only the ecdh key generation algorithm and key derivation function (SHA-256).
Since the enrollment phase is presumed to be expensive, due to writing in eNVM memory, the test was also performed 10 times with key enrollment, to get an idea of its potential performance cost.

A higher time of 0.577 seconds without enrollment and 1.764s with, compared to the previous operations is expected due to the higher cost of operations with asymmetric keys.
However, comparing both values we can conclude saving the key in memory, has most likely the higher performance impact on the operation.
This result is congruent with the one obtained by \cite{parrinha2017flexible} of 0.57s per ECC scalar multiplication.
Thus we can conclude, the scalar multiplication is the second most expensive operation, after the key enrollment, since the key derivation function has a negligible impact on the processing time (0.577s with the function vs 0.57s without).

% -----------------------------------------------------
% -----------------------------------------------------
\section{Requirements}\label{chap:evaluation:requirements}

A M2S090TS smartfusion2 evaluation kit is priced at 384â‚¬ \cite{smartfusionPrice}.

% ------------- Requirements ------------------
% Devices should be distributable to individuals or entities with one or more individuals;
% The system must allow communications between individuals representing themselves or an entity;
% The system must be responsible for securing all communications against any sort of attacks;
% The device should be independent from user's personal computers;
% Users should be able to create secure communications with available and new entities;
% m New secure connections should be created, if existing communications are suspected to be compromised;
% It should provide an easy-to-use interface by everyone, including non-technical people;
% It should have a relatively low cost, to allow distribution of several devices among multiple people;
% Only authorized individuals should be able to use the device.
% ---------------------------------------------

% secure comms - aes and hmac services are not dpa resistant, so keys should be regularly replaced to avoid enough data which enables an attacker to break encryption. On the other hand this is only possible if the attacker has physical access to the device or potentially with some type of malware on the user's computer.
% key generation - needs assymetric keys to generate new keys with public keys and salt traded beforehand - can be not user friendly
